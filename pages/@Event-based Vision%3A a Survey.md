title:: @Event-based Vision: a Survey
pages:: 25
item-type:: [[journalArticle]]
original-title:: Event-based Vision: a Survey
language:: en
authors:: [[G Gallego]], [[T Delbruck]], [[G Orchard]], [[C Bartolozzi]], [[B Taba]], [[A Censi]], [[S Leutenegger]], [[A Davison]], [[J Conradt]], [[K Daniilidis]], [[D Scaramuzza]]
library-catalog:: Zotero
links:: [Local library](zotero://select/library/items/GELFP8HT), [Web library](https://www.zotero.org/users/8224007/items/GELFP8HT)

- [[Abstract]]
	- Event cameras are bio-inspired sensors that work radically different from traditional cameras. Instead of capturing images at a ﬁxed rate, they measure per-pixel brightness changes asynchronously. This results in a stream of events, which encode the time, location and sign of the brightness changes. Event cameras posses outstanding properties compared to traditional cameras: very high dynamic range (140 dB vs. 60 dB), high temporal resolution (in the order of µs), low power consumption, and do not suffer from motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as high speed and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging ﬁeld of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic ﬂow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efﬁcient, bio-inspired way for machines to perceive and interact with the world.
- [[Atachments]]
	- [gallego_event-based_vision.pdf](zotero://select/library/items/GWC2FF82) {{zotero-linked-file "Gallego/gallego_event-based_vision.pdf"}}